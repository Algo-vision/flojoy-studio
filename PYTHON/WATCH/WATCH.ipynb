{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from plotly import plot\n",
    "import plotly.offline as pyo\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "# from utils import PlotlyJSONEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test-fc-loop.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = fc['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in elems:\n",
    "    if 'id' in el:\n",
    "        print(el['id'].split('-')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(elems)):\n",
    "    el = elems[i]\n",
    "    if 'source' not in el:\n",
    "        DG.add_node(i+1, pos=(el['position']['x'], el['position']['y']),id=el['id'])\n",
    "        elems[i]['index'] = i+1\n",
    "        elems[i]['label'] = el['id'].split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.get_node_attributes(DG,'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(DG, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label_dict = {}\n",
    "def get_tuple(edge):\n",
    "    e = [-1, -1]\n",
    "    src_id = edge['source']\n",
    "    tgt_id = edge['target']\n",
    "\n",
    "    if tgt_id not in edge_label_dict.keys():\n",
    "            edge_label_dict[tgt_id] = []\n",
    "\n",
    "    edge_label_dict[tgt_id].append({\n",
    "        'source': src_id,\n",
    "        'label': edge['label'] if 'label' in edge else \"default\",\n",
    "        'sourceHandle': edge['sourceHandle'],\n",
    "        'targetHandle': edge['targetHandle']\n",
    "    })\n",
    "\n",
    "    # iterate through all nodes looking for matching edge\n",
    "    for el in elems:\n",
    "        if 'id' in el:\n",
    "            if el['id'] == src_id:\n",
    "                e[0] = el['index']\n",
    "            elif el['id'] == tgt_id:\n",
    "                e[1] = el['index']\n",
    "    return tuple(e)\n",
    "edges = fc['edges']\n",
    "for i in range(len(edges)):\n",
    "    el = edges[i]\n",
    "\n",
    "    # element is an edge\n",
    "    e = get_tuple(el)\n",
    "    DG.add_edge(*e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(DG.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(DG.edges)\n",
    "print(edges)\n",
    "# for edge in edges:\n",
    "#     print(edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{el['id']: el['type']} for el in elems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(DG, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add labels to DG nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "\n",
    "for el in elems:\n",
    "    # if element is not a node\n",
    "    if 'source' not in el:\n",
    "        labels[el['index']] = el['data']['func']\n",
    "                \n",
    "nx.set_node_attributes(DG, labels, 'cmd')\n",
    "nx.draw(DG, pos, with_labels=True, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_by_id = dict()\n",
    "# for n, nd in DG.nodes().items():\n",
    "#     if n is not None:\n",
    "#         nodes_by_id[n] = nd\n",
    "# nodes_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.dfs_tree(DG, source=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, nd in DG.nodes().items():\n",
    "    print('node', n, 'node data', nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_data_by_id():\n",
    "    nodes_by_id = dict()\n",
    "    for n, nd in DG.nodes().items():\n",
    "        nodes_by_id[n] = nd\n",
    "    return nodes_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nx.topological_sort(DG):\n",
    "    print(n, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DFS Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self,DG,edge_label_dict):\n",
    "        self.DG = DG\n",
    "        self.edges = DG.edges\n",
    "        self.nodes = DG.nodes\n",
    "        self.edge_label_dict = edge_label_dict\n",
    "        self.adjList = {}\n",
    "        self.make_adjancency_list()\n",
    "\n",
    "    def get_node_data_by_id(self):\n",
    "        nodes_by_id = dict()\n",
    "        for n, nd in self.DG.nodes().items():\n",
    "            nodes_by_id[n] = nd\n",
    "        return nodes_by_id\n",
    "\n",
    "    def make_adjancency_list(self):\n",
    "        for (src,dest) in self.edges:\n",
    "\n",
    "            if src not in self.adjList.keys():\n",
    "                self.adjList[src] = []\n",
    "\n",
    "            for value in self.edge_label_dict[self.get_node_data_by_id()[dest]['id']]:\n",
    "                \n",
    "                if value['source'] == self.get_node_data_by_id()[src]['id']:\n",
    "                    sourceHandle = value['sourceHandle']\n",
    "\n",
    "            self.adjList[src].append({\n",
    "                'target_node_id': self.get_node_data_by_id()[dest]['id'],\n",
    "                'src_node_id':self.get_node_data_by_id()[src]['id'],\n",
    "                'target_node':dest,\n",
    "                'handle':sourceHandle\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_node_data_by_id()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(graph,source,discovered,current_loop_nodes,hashmap):\n",
    "\n",
    "    cmd = get_node_data_by_id()[source]['cmd']\n",
    "    id = get_node_data_by_id()[source]['id']\n",
    "\n",
    "    # print(cmd)\n",
    "\n",
    "    if source not in graph.adjList.keys():\n",
    "        hashmap[id] = current_loop_nodes.copy()\n",
    "        discovered[source-1] = True\n",
    "        return\n",
    "\n",
    "    body = []\n",
    "    end = []\n",
    "\n",
    "    # checking if the source is LOOP type\n",
    "    if cmd == 'LOOP':\n",
    "\n",
    "        current_loop_nodes.append(id)\n",
    "\n",
    "        # find the end & body source Handle\n",
    "        for value in graph.adjList[source]:\n",
    "            if value['handle'] == 'body':\n",
    "                body.append(value['target_node'])\n",
    "            if value['handle'] == 'end':\n",
    "                end.append(value['target_node'])\n",
    "    \n",
    "        # traversing the body node first\n",
    "        for value in body:\n",
    "            if not discovered[value-1]:\n",
    "                DFS(graph=graph,source=value,discovered=discovered,current_loop_nodes=current_loop_nodes,hashmap=hashmap)\n",
    "\n",
    "        current_loop_nodes.pop()\n",
    "        hashmap[id] = current_loop_nodes.copy()\n",
    "\n",
    "        for value in end:\n",
    "            if not discovered[value-1]:\n",
    "                DFS(graph=graph,source=value,discovered=discovered,current_loop_nodes=current_loop_nodes,hashmap=hashmap)\n",
    "        \n",
    "        discovered[source-1] = True\n",
    "    else:\n",
    "        for value in graph.adjList[source]:\n",
    "            if not discovered[value['target_node']-1]:\n",
    "                DFS(graph=graph,source=value['target_node'],discovered=discovered,current_loop_nodes=current_loop_nodes,hashmap=hashmap)\n",
    "        hashmap[id] = current_loop_nodes.copy()        \n",
    "        discovered[source-1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(DG,edge_label_dict)\n",
    "discovered = [False] * len(list(DG.nodes))\n",
    "\n",
    "# finding the source of dfs tree\n",
    "dfs_source = []\n",
    "for node in DG.nodes:\n",
    "    if len(list(DG.predecessors(node))) == 0:\n",
    "        dfs_source.append(node)\n",
    "\n",
    "hash_map = {}\n",
    "current_loop_nodes = []\n",
    "DFS(graph=graph,source=dfs_source[0],discovered=discovered,current_loop_nodes=current_loop_nodes,hashmap = hash_map)\n",
    "\n",
    "hash_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_map_loop = {}\n",
    "for key,value in hash_map.items():\n",
    "    if len(value) > 0:\n",
    "        for loop_id in value:\n",
    "            if loop_id not in hash_map_loop.keys():\n",
    "                hash_map_loop[loop_id] = []\n",
    "            hash_map_loop[loop_id].append(key)\n",
    "hash_map_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topological_sorting_list = [get_node_data_by_id()[node]['id'] for node in list(nx.topological_sort(DG))]\n",
    "topological_sorting_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_order_loopnodes = {}\n",
    "\n",
    "for key,nodes in hash_map_loop.items():\n",
    "    sorting_order = [topological_sorting_list.index(node) for node in nodes]\n",
    "    sorting_order.sort()\n",
    "    sorting_order_loopnodes[key] = [topological_sorting_list[node_id] for node_id in sorting_order]\n",
    "    \n",
    "sorting_order_loopnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing dependant loop nodes\n",
    "for key,parents in hash_map.items():\n",
    "    if 'LOOP' in key and len(parents) > 0:\n",
    "        for parent in parents:\n",
    "\n",
    "            parent_loop_nodes = sorting_order_loopnodes[parent]\n",
    "            child_loop_nodes = sorting_order_loopnodes[key]\n",
    "\n",
    "            print('parent loop node: ',parent_loop_nodes)\n",
    "            print('child loop node: ',child_loop_nodes)\n",
    "\n",
    "            for node in child_loop_nodes:\n",
    "                parent_loop_nodes.remove(node) if node in parent_loop_nodes else ''\n",
    "\n",
    "            sorting_order_loopnodes[parent] = parent_loop_nodes\n",
    "sorting_order_loopnodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDIS & IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis import Redis\n",
    "from rq import Queue\n",
    "from rq.job import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Redis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Redis()\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue(connection=conn)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENERATORS import *\n",
    "from TRANSFORMERS import *\n",
    "from VISORS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = getattr(globals()['LINSPACE'], 'LINSPACE')\n",
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.enqueue(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_success(job, connection, result, *args, **kwargs):\n",
    "    print('success', result)\n",
    "\n",
    "def report_failure(job, connection, type, value, traceback):\n",
    "    print('failure')\n",
    "    print(job, connection, type, value, traceback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topological_sorting = nx.topological_sort(DG)\n",
    "nodes_by_id = get_node_data_by_id()\n",
    "\n",
    "for n in topological_sorting:\n",
    "\n",
    "    cmd = nodes_by_id[n]['cmd']\n",
    "    ctrls = dict()\n",
    "\n",
    "    if cmd.replace('.','',1).isdigit():\n",
    "        ctrls['constant'] = cmd\n",
    "        cmd = 'CONSTANT'   \n",
    "    \n",
    "    func = getattr(globals()[cmd], cmd)\n",
    "    job_id = 'job_id_{0}'.format(n)\n",
    "\n",
    "    print('>>> visiting node *** {0} *** ({1})'.format(cmd, n))\n",
    "    print('Queueing function... ...', func)\n",
    "    \n",
    "    node_predecessors = DG.predecessors(n)\n",
    "    \n",
    "    if len(list(node_predecessors)) == 0:\n",
    "        print ('{0} ({1}) has no predecessors'.format(cmd, n))\n",
    "        q.enqueue(func, job_id = job_id, kwargs={'ctrls': ctrls})\n",
    "    else:\n",
    "        previous_job_ids = []\n",
    "        for p in DG.predecessors(n):\n",
    "            prev_cmd = DG.nodes[p]['cmd']\n",
    "            prev_job_id = 'job_id_{0}'.format(p)\n",
    "            previous_job_ids.append(prev_job_id)\n",
    "            print(prev_cmd, 'is a predecessor to', cmd)\n",
    "        q.enqueue(func,\n",
    "            job_id = job_id,\n",
    "            kwargs={'ctrls': ctrls, 'previous_job_ids': previous_job_ids},            \n",
    "            depends_on = previous_job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_by_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get end nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_nodes = [x for x in DG.nodes() if DG.out_degree(x)==0 and DG.in_degree(x)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_node_results = []\n",
    "\n",
    "for n in end_nodes:\n",
    "    job_id = 'job_id_{0}'.format(n)\n",
    "    nd = get_node_data_by_id()[n]\n",
    "    print(nd)\n",
    "    job = Job.fetch(job_id, connection=Redis())\n",
    "    payload = job.result\n",
    "    print(str(payload['data'][0]['type']))\n",
    "    end_node_results.append({nd['cmd']: payload})\n",
    "    \n",
    "end_node_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results.json\", \"w\")\n",
    "f.write(json.dumps(end_node_results, cls=PlotlyJSONEncoder))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all functions in folder module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/jackparmer/Desktop/projects/daq-labs/PYTHON/WATCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to FUNCTIONS folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../FUNCTIONS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from GENERATORS import *\n",
    "from TRANSFORMERS import *\n",
    "from VISORS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCATTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINE.SINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "code =inspect.getsource(getattr(globals()['SCATTER'], 'SCATTER'));\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('../FUNCTIONS/SIMULATIONS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['GENERATORS'] = __import__('GENERATORS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flojoy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d55ae75fe0eb663b197949bccf7e5b6b79077fe894ce47bfd75fb7a3d0d89327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
